# ViveProEye_OculomotorLab
Unity framework for scientific research using HTC Vive Pro Eye and SRanipal SDK. Includes high-frequency eye tracking (120 Hz), gaze-contingent rendering, and experimental tasks for detecting saccades, smooth pursuits, and vergence. 

üìç Overview
This Unity framework is designed to fully exploit the capabilities of the HTC Vive Pro Eye for scientific research in oculomotor behavior. It uses the SRanipal SDK to access high-frequency eye tracking data (120 Hz), enabling precise measurement and analysis of eye movements in immersive virtual reality environments.
The framework includes tools for data logging, gaze-contingent visualization, and customizable experimental tasks, making it ideal for clinical studies, perceptual experiments, and rehabilitation research.

üß† Key Features

120 Hz eye tracking via SRanipal (Tobii).
Real-time logging of eye data including gaze origin, direction, pupil metrics, and head pose.
Gaze-contingent rendering: each eye sees only its own gaze visualizer.
Independent rendering for each eye using two Unity cameras (XR Left Eye, XR Right Eye).
Keyboard control for calibration and data recording.
Low-pass filtering for noise reduction in gaze vectors.
Modular structure for integration with other Unity scenes or scientific pipelines.


üß™ Experimental Tasks
Inside the folder OcularDetectTest, you will find three sample scenes designed to elicit and record specific oculomotor behaviors:
1. SaccadesTask

Presents a sequence of discrete visual targets at different spatial positions.
Designed to elicit saccadic eye movements.
Automatically logs eye data during the task.

2. SmoothPursuitsTask
 
Displays a moving sphere oscillating horizontally.
Designed to elicit smooth pursuit movements.
Eye data is recorded while the subject tracks the moving target.

3. VergenceTask

Presents a sphere moving back and forth along the Z-axis.
Designed to elicit vergence movements (convergence/divergence).
Eye data is recorded during depth tracking.

Each task includes:

A fixed head camera position.
A visual stimulus (Sphere) that activates after a short delay.
Automatic start/stop of data recording.
Export of data in .txt format with structured headers.


üéÆ Keyboard Controls
Handled via InputManager.cs:

S ‚Üí Start data recording
E ‚Üí Stop data recording
C ‚Üí Launch eye calibration (SRanipal)


üìÅ Data Output
Each task generates a .txt file containing:

Unity time and SRanipal timestamp
Frame index
Eye validity and openness
Pupil diameter and position
Gaze origin and direction (left, right, combined)
Head position and rotation
Gaze-contingency vectors

The header is automatically written at the start of each recording session.

üß™ Data Analysis
Collected data can be analyzed using the Python-based tool available at:

https://github.com/MattiaBarbieri/XR_Ocular_Movements_Detection

This tool integrates the REMoDNaV (Robust Eye Movement Detection for Natural Viewing) algorithm to automatically detect:

Saccades
Smooth pursuits
Fixations
Vergence patterns

It includes:

Preprocessing of raw gaze data
Visualization of eye movement trajectories
Statistical summaries and exportable results
Compatibility with the .txt files generated by this Unity framework


üß∞ Requirements

Unity 2022.3.32f1
OpenXR Plugin
SRanipal SD
HTC Vive Pro Eye
Tobii Runtime installed


üî¨ Applications

Oculomotor behavior analysis (saccades, pursuits, vergence)
Visual perception and attention studies
Clinical training and assessment
